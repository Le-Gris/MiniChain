{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67aac089",
   "metadata": {},
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438e211",
   "metadata": {},
   "source": [
    "\"ChatGPT\" like examples.  Adapted from\n",
    "[LangChain](https://langchain.readthedocs.io/en/latest/modules/memory/examples/chatgpt_clone.html)'s\n",
    "version of this [blog\n",
    "post](https://www.engraved.blog/building-a-virtual-machine-inside/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7566247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T15:52:43.763097Z",
     "iopub.status.busy": "2023-02-27T15:52:43.762316Z",
     "iopub.status.idle": "2023-02-27T15:52:43.981411Z",
     "shell.execute_reply": "2023-02-27T15:52:43.980694Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from minichain import TemplatePrompt, start_chain\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import minichain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98319de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T15:52:43.986455Z",
     "iopub.status.busy": "2023-02-27T15:52:43.985267Z",
     "iopub.status.idle": "2023-02-27T15:52:43.991159Z",
     "shell.execute_reply": "2023-02-27T15:52:43.990546Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class State:\n",
    "    memory: List[Tuple[str, str]]\n",
    "    human_input: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26127ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T15:52:43.995922Z",
     "iopub.status.busy": "2023-02-27T15:52:43.994645Z",
     "iopub.status.idle": "2023-02-27T15:52:44.001075Z",
     "shell.execute_reply": "2023-02-27T15:52:44.000396Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MemoryPrompt(TemplatePrompt):\n",
    "    template_file = \"chatgpt.pmpt.tpl\"\n",
    "    def parse(self, out, inp):\n",
    "        result = out.split(\"Assistant:\")[-1]\n",
    "        memory = inp.memory if len(inp.memory) < 2 else inp.memory[1:]\n",
    "        return State(memory + [(inp.human_input, result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb005ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T15:52:44.006061Z",
     "iopub.status.busy": "2023-02-27T15:52:44.004578Z",
     "iopub.status.idle": "2023-02-27T15:52:44.011181Z",
     "shell.execute_reply": "2023-02-27T15:52:44.010509Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_human = [\n",
    "    \"I want you to act as a Linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do not write explanations. Do not type commands unless I instruct you to do so. When I need to tell you something in English I will do so by putting text inside curly brackets {like this}. My first command is pwd.\",\n",
    "    \"ls ~\",\n",
    "    \"cd ~\",\n",
    "    \"{Please make a file jokes.txt inside and put some jokes inside}\",\n",
    "    \"\"\"echo -e \"x=lambda y:y*5+3;print('Result:' + str(x(6)))\" > run.py && python3 run.py\"\"\",\n",
    "    \"\"\"echo -e \"print(list(filter(lambda x: all(x%d for d in range(2,x)),range(2,3**10)))[:10])\" > run.py && python3 run.py\"\"\",\n",
    "    \"\"\"echo -e \"echo 'Hello from Docker\" > entrypoint.sh && echo -e \"FROM ubuntu:20.04\\nCOPY entrypoint.sh entrypoint.sh\\nENTRYPOINT [\\\"/bin/sh\\\",\\\"entrypoint.sh\\\"]\">Dockerfile && docker build . -t my_docker_image && docker run -t my_docker_image\"\"\",\n",
    "    \"nvidia-smi\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbc30aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T15:52:44.015810Z",
     "iopub.status.busy": "2023-02-27T15:52:44.014617Z",
     "iopub.status.idle": "2023-02-27T15:53:16.419091Z",
     "shell.execute_reply": "2023-02-27T15:53:16.418408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I want you to act as a Linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do not write explanations. Do not type commands unless I instruct you to do so. When I need to tell you something in English I will do so by putting text inside curly brackets {like this}. My first command is pwd.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srush/Projects/MiniChain/venv/lib/python3.10/site-packages/eliot/json.py:22: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if isinstance(o, (numpy.bool, numpy.bool_)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "```\n",
      "$ pwd\n",
      "/\n",
      "```\n",
      "Human: ls ~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "```\n",
      "$ ls ~\n",
      "Desktop/ Documents/ Downloads/ Music/ Pictures/ Public/ Templates/ Videos/\n",
      "```\n",
      "Human: cd ~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  \n",
      "```\n",
      "$ cd ~\n",
      "$ pwd\n",
      "/home/username\n",
      "```\n",
      "Human: {Please make a file jokes.txt inside and put some jokes inside}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "\n",
      "```\n",
      "$ touch jokes.txt\n",
      "$ echo \"Why did the chicken cross the road? To get to the other side!\" >> jokes.txt\n",
      "$ echo \"What did the fish say when it hit the wall? Dam!\" >> jokes.txt\n",
      "$ echo \"Why did the scarecrow win the Nobel Prize? Because he was outstanding in his field!\" >> jokes.txt\n",
      "```\n",
      "Human: echo -e \"x=lambda y:y*5+3;print('Result:' + str(x(6)))\" > run.py && python3 run.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "\n",
      "```\n",
      "$ echo -e \"x=lambda y:y*5+3;print('Result:' + str(x(6)))\" > run.py\n",
      "$ python3 run.py\n",
      "Result: 33\n",
      "```\n",
      "Human: echo -e \"print(list(filter(lambda x: all(x%d for d in range(2,x)),range(2,3**10)))[:10])\" > run.py && python3 run.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "\n",
      "```\n",
      "$ echo -e \"print(list(filter(lambda x: all(x%d for d in range(2,x)),range(2,3**10)))[:10])\" > run.py\n",
      "$ python3 run.py\n",
      "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n",
      "```\n",
      "Human: echo -e \"echo 'Hello from Docker\" > entrypoint.sh && echo -e \"FROM ubuntu:20.04\n",
      "COPY entrypoint.sh entrypoint.sh\n",
      "ENTRYPOINT [\"/bin/sh\",\"entrypoint.sh\"]\">Dockerfile && docker build . -t my_docker_image && docker run -t my_docker_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "\n",
      "```\n",
      "$ echo -e \"echo 'Hello from Docker\" > entrypoint.sh\n",
      "$ echo -e \"FROM ubuntu:20.04\n",
      "COPY entrypoint.sh entrypoint.sh\n",
      "ENTRYPOINT [\"/bin/sh\",\"entrypoint.sh\"]\">Dockerfile\n",
      "$ docker build . -t my_docker_image\n",
      "$ docker run -t my_docker_image\n",
      "Hello from Docker\n",
      "```\n",
      "Human: nvidia-smi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "\n",
      "```\n",
      "$ nvidia-smi\n",
      "Sat May 15 21:45:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P0    28W / 250W |      0MiB /  10240MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running\n"
     ]
    }
   ],
   "source": [
    "with minichain.start_chain(\"chatgpt\") as backend:\n",
    "    prompt = MemoryPrompt(backend.OpenAI())\n",
    "    state = State([])\n",
    "    for t in fake_human:\n",
    "        state.human_input = t\n",
    "        print(f\"Human: {t}\")\n",
    "        state = prompt(state)\n",
    "        print(f\"Assistant: {state.memory[-1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31ecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "minichain",
   "language": "python",
   "name": "minichain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
